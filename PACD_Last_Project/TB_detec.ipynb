{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2b705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from skimage.feature import local_binary_pattern,  graycomatrix, graycoprops, hog\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7348b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ammar-y530/Documents/S2/PACD/PACD_Assignment/small_dataset/ChestXRay/ChestXRay/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacbe7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ptb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ptb\n",
       "0  1000    0\n",
       "1  1001    0\n",
       "2  1002    0\n",
       "3  1003    1\n",
       "4  1004    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/ammar-y530/Documents/S2/PACD/PACD_Assignment/small_dataset/MetaData.csv\", index_col=False)\n",
    "data = data.drop(columns=[\"gender\", \"age\", \"county\", \"remarks\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcf5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class utils():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def display_image(title, image):\n",
    "        cv2.imshow(title, image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    @staticmethod\n",
    "    def display_histogram(image):\n",
    "        plt.hist(np.array(image).flatten(), bins=256, color='gray')\n",
    "        plt.title('Histogram')\n",
    "        plt.xlabel('Intensitas')\n",
    "        plt.ylabel('Frekuensi')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_data_to_gray(path):\n",
    "        folder_path = os.path.join(path, 'image')\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                \n",
    "                if os.path.isfile(img_path):\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        print(f\"{file} : None\")\n",
    "                    else:\n",
    "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                        cv2.imwrite(img_path, gray)\n",
    "                        # print(f\"{file} : Non None\")\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_check(path):\n",
    "        folder_path = os.path.join(path, 'image')\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "\n",
    "                img = Image.open(img_path)\n",
    "                img = np.array(img)\n",
    "                \n",
    "                if img is None:\n",
    "                    print(f\"{file}: Cannot read file\")\n",
    "                    continue\n",
    "\n",
    "                # Cek jumlah channel\n",
    "                if len(img.shape) == 2:\n",
    "                    # print(f\"{img_path} pass\")\n",
    "                    continue\n",
    "                elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                    print(img.shape)\n",
    "                    print(f\"{img_path} has 3 dimenstion\")\n",
    "                    return 0\n",
    "                else:\n",
    "                    return 0    \n",
    "        else:\n",
    "            print(\"Folder Kosong\")\n",
    "        \n",
    "        return 1\n",
    "\n",
    "class preprocess():\n",
    "    def __init__(self):\n",
    "        self.preprocessed_folder = 'preprocessed_img'\n",
    "        self.image_folder = 'image'\n",
    "        self.mask_folder = 'mask'\n",
    "    \n",
    "    def apply_mask(self, image, mask):\n",
    "        mask_bin = (mask > 0).astype(np.uint8)\n",
    "        masked_image = image * mask_bin\n",
    "        return masked_image\n",
    "    \n",
    "    def crop(self, image, mask):\n",
    "        ys, xs = np.where(mask > 0)\n",
    "\n",
    "        if len(xs) == 0 or len(ys) == 0:\n",
    "            raise ValueError(\"Mask tidak valid\")\n",
    "        \n",
    "        xmin, xmax = np.min(xs), np.max(xs)\n",
    "        ymin, ymax = np.min(ys), np.max(ys)\n",
    "\n",
    "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "        return cropped_image\n",
    "    \n",
    "    def resize(self, image, target=(512, 512)):\n",
    "        h, w = image.shape[:2]\n",
    "        target_w, target_h = target\n",
    "\n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "\n",
    "        resized = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "        pad_x = target_w - new_w\n",
    "        pad_y = target_h - new_h\n",
    "\n",
    "        padded = cv2.copyMakeBorder(\n",
    "            resized,\n",
    "            pad_y // 2, pad_y - pad_y // 2,\n",
    "            pad_x // 2, pad_x - pad_x // 2,\n",
    "            cv2.BORDER_CONSTANT,\n",
    "            value=0\n",
    "        )\n",
    "        return padded\n",
    "\n",
    "    def clahe(self, image):\n",
    "        clahe = cv2.createCLAHE(clipLimit=5)\n",
    "        clahe_img = np.clip(clahe.apply(image) + 30, 0, 255).astype(np.uint8)\n",
    "        # _, threshold_img = cv2.threshold(image, 155, 255, cv2.THRESH_BINARY)\n",
    "        return clahe_img\n",
    "    \n",
    "    def median_blur(self, image):\n",
    "        blured_image = cv2.medianBlur(image, 5)\n",
    "        return blured_image\n",
    "    \n",
    "    def preprocessing(self, folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            print(file)\n",
    "\n",
    "        processed_image_folder = os.path.join(folder_path, self.preprocessed_folder)\n",
    "\n",
    "        if not os.path.exists(processed_image_folder):\n",
    "            os.makedirs(processed_image_folder)\n",
    "            print(f\"Created {processed_image_folder}\")\n",
    "\n",
    "        image_folder = os.path.join(folder_path, self.image_folder)\n",
    "        mask_folder = os.path.join(folder_path, self.mask_folder)\n",
    "\n",
    "        if not os.path.isdir(image_folder):\n",
    "            print(\"Folder image tidak ditemukan!\")\n",
    "            return\n",
    "\n",
    "        for file in os.listdir(image_folder):\n",
    "            img_path = os.path.join(image_folder, file)\n",
    "            mask_path = os.path.join(mask_folder, file)\n",
    "\n",
    "            if not os.path.isfile(img_path):\n",
    "                continue\n",
    "\n",
    "            img = Image.open(img_path)\n",
    "            mask = Image.open(mask_path)\n",
    "            img = np.array(img)\n",
    "            mask = np.array(mask)\n",
    "\n",
    "            masked_image = self.apply_mask(img, mask)\n",
    "            cropped_image = self.crop(masked_image, mask)\n",
    "            resized_image = self.resize(cropped_image, (1024, 1024))\n",
    "            clahe_result = self.clahe(resized_image)\n",
    "            median_blur_result = self.median_blur(clahe_result)\n",
    "\n",
    "            pre_normalized = median_blur_result.astype(np.float32)\n",
    "            normalized = pre_normalized / 255.0\n",
    "\n",
    "            save_img = (normalized * 255).astype(np.uint8)\n",
    "            output_path = os.path.join(processed_image_folder, file)\n",
    "            cv2.imwrite(output_path, save_img)\n",
    "            # np.save(output_path.replace('.png', '.npy'), normalized)\n",
    "            # print(f\"Saved: {output_path}\")\n",
    "\n",
    "class featureExtract():\n",
    "    def __init__(self):\n",
    "        self.preprocessed_folder = 'preprocessed_img'\n",
    "        # lbp\n",
    "        self.radius = 2\n",
    "        self.n_points = 8 * self.radius\n",
    "\n",
    "        #hog\n",
    "        self.hog_dim = 5000\n",
    "\n",
    "    def lbp(self, image):\n",
    "        radius = 2\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "        hist, _ = np.histogram(\n",
    "            lbp.ravel(),\n",
    "            bins=np.arange(0, self.n_points + 3),\n",
    "            range=(0, self.n_points + 2)\n",
    "        )\n",
    "        hist = hist.astype(float)\n",
    "        hist /= hist.sum()\n",
    "        return hist\n",
    "    \n",
    "    def glcm(self, image):\n",
    "        glcm = graycomatrix(image, [1], [0], symmetric=True, normed=True)\n",
    "        props = [\"contrast\", \"dissimilarity\", \"homogeneity\", \n",
    "                \"energy\", \"correlation\", \"ASM\"]\n",
    "        features = [graycoprops(glcm, p)[0,0] for p in props]\n",
    "        return np.array(features)\n",
    "\n",
    "    def hog(self, image):\n",
    "        hog_features = hog(image,\n",
    "                        orientations=9,\n",
    "                        pixels_per_cell=(16,16),\n",
    "                        cells_per_block=(2,2),\n",
    "                        block_norm=\"L2-Hys\",\n",
    "                        feature_vector=True)\n",
    "        return hog_features\n",
    "    \n",
    "    def pca(self, hog):\n",
    "        pca = PCA(n_components=200)\n",
    "        hog_pca = pca.fit_transform(hog)\n",
    "        return hog_pca\n",
    "    \n",
    "    def feature_extract(self, df, folder_path):\n",
    "        image_folder = os.path.join(folder_path, self.preprocessed_folder)\n",
    "        print(\"Membaca folder:\", image_folder)\n",
    "\n",
    "        # Tambahkan kolom lbp (jika belum ada)\n",
    "        lbp_len = self.n_points + 2\n",
    "        for i in range(lbp_len):\n",
    "            col = f\"lbp_{i}\"\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0.0\n",
    "\n",
    "        # Kolom GLCM\n",
    "        glcm_cols = [\"glcm_contrast\", \"glcm_dissimilarity\", \"glcm_homogeneity\",\n",
    "                    \"glcm_energy\", \"glcm_correlation\", \"glcm_ASM\"]\n",
    "        for col in glcm_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0.0\n",
    "\n",
    "        # Kolom HOG (200 fitur cukup aman)\n",
    "        hog_dim = self.hog_dim\n",
    "        for i in range(hog_dim):\n",
    "            col = f\"hog_{i}\"\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0.0\n",
    "\n",
    "        # Loop gambar\n",
    "        for idx, row in df.iterrows():\n",
    "            img_name = str(int(row[\"id\"])) + \".png\"\n",
    "            img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(\"Gambar tidak ditemukan:\", img_path)\n",
    "                continue\n",
    "\n",
    "            # --- LBP ---\n",
    "            lbp_result = self.lbp(img)\n",
    "            for i in range(lbp_len):\n",
    "                df.at[idx, f\"lbp_{i}\"] = lbp_result[i]\n",
    "\n",
    "            # --- GLCM ---\n",
    "            glcm_feat = self.glcm(img)\n",
    "            for i, col in enumerate(glcm_cols):\n",
    "                df.at[idx, col] = glcm_feat[i]\n",
    "\n",
    "            # --- HOG (batasi fitur ke 200 pertama) ---\n",
    "            hog_feat = self.hog(img)\n",
    "            hog_vec = hog_feat[:self.hog_dim]          # ambil 200 fitur pertama\n",
    "            hog_pca = self.pca(hog_vec)\n",
    "\n",
    "            for i in range(len(hog_pca)):\n",
    "                df.at[idx, f\"hog_{i}\"] = hog_pca[i]\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ecc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.convert_data_to_gray(path)\n",
    "# ok = utils.dataset_check(path)\n",
    "# if ok:\n",
    "#     print(\"Dataset ready to use\")\n",
    "# else:\n",
    "#     print(\"Dataset unready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59050d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep = preprocess()\n",
    "# prep.preprocessing(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae924233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membaca folder: /home/ammar-y530/Documents/S2/PACD/PACD_Assignment/small_dataset/ChestXRay/ChestXRay/preprocessed_img\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fe \u001b[38;5;241m=\u001b[39m featureExtract()\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 257\u001b[0m, in \u001b[0;36mfeatureExtract.feature_extract\u001b[0;34m(self, df, folder_path)\u001b[0m\n\u001b[1;32m    255\u001b[0m hog_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhog(img)\n\u001b[1;32m    256\u001b[0m hog_vec \u001b[38;5;241m=\u001b[39m hog_feat[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhog_dim]          \u001b[38;5;66;03m# ambil 200 fitur pertama\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m hog_pca \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhog_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hog_pca)):\n\u001b[1;32m    260\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhog_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hog_pca[i]\n",
      "Cell \u001b[0;32mIn[8], line 206\u001b[0m, in \u001b[0;36mfeatureExtract.pca\u001b[0;34m(self, hog)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpca\u001b[39m(\u001b[38;5;28mself\u001b[39m, hog):\n\u001b[1;32m    205\u001b[0m     pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m     hog_pca \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hog_pca\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:468\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     U, S, _, X, x_is_centered, xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:505\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA with svd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for Array API inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    497\u001b[0m     )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_solver\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/pacd/lib/python3.9/site-packages/sklearn/utils/validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1092\u001b[0m             )\n\u001b[0;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "fe = featureExtract()\n",
    "result = fe.feature_extract(data,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.to_csv(\"fitur.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = Image.open(\"C:\\\\Users\\\\Muhammad Ammar M\\\\Documents\\\\Kuylah S2\\\\Pengolahan dan Analisis Citra Digital\\\\PACD_Assignment\\\\small dataset\\\\ChestXRay\\\\ChestXRay\\\\preprocessed_img\\\\1000.png\")\n",
    "img = np.array(img)\n",
    "\n",
    "# Inspeksi Gambar\n",
    "# utils.display_image(\"Test\", img)\n",
    "# utils.display_histogram(img)\n",
    "# print(img.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
